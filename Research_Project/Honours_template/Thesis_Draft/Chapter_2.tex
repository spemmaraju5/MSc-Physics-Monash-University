\section{Structure of the LHCb Detector}
The Large Hadron Collider beauty (LHCb) detector is a single-arm spectrometer possessing a forward angular coverage from
approximately 10 mrad to 300 (250) mrad in the bending (non-bending) plane \cite{https://doi.org/10.48550/arxiv.0910.1740}
The structure of the detector is motivated by the fact that both the $b$ and the $\bar{b}$ hadrons are predominantly produced in the
same forward or backward cone. The components that enable the identification of particles, and aid the deduction of their properties include
the vertex locator system (VELO), the tracking system, comprising of a Trigger Tracker (a silicon microstrip detector, TT) located in front 
of the magnet, three tracking stations behind the magnet made up of silicon microstrips in the inner and outer parts (labelled IT and OT respectively),
two Ring Imaging Cherenkov counters (labelled RICH1 and RICH2 respectively), as well as a calorimeter system, comprising of a Scintillating Pad Detector and Preshower
(SPD/PS) and electromagnetic and hadronic calorimeters (ECAL and HCAL respectively) \cite{https://doi.org/10.48550/arxiv.0910.1740}. The layout of the LHCb spectrometer including the relative positions of the components described above, is illustrated in Figure \ref{LHCbDetector}.\\
\\
Of the abovementioned components, the dipole magnet, VELO, and ECAL play a significant role
in the analysis of the decay described in Section \ref{DecayProcess}. The structure of these sections of the
detector is further elaborated on in the sections that follow.
\begin{figure}[H]
    \centering
    \includegraphics[scale = 0.45]{LHCbDetector.jpg}
    \caption{Diagram of the LHCb detector illustrating its various components. The coordinate system is oriented such that the beam is directed along the $z$ axis, and the $y$ axis is oriented along the vertical. Figure sourced from \cite{AbellanBeteta:2020amj}}
    \label{LHCbDetector}
\end{figure}
\subsection{Vertex Locator (VELO)}
The Vertex Locator (VELO) is a silicon-tracking detector in the spectrometer of the LHCb experiment shown in Figure (\ref{LHCbDetector}) above, and is responsible for the high-precision reconstruction of the primary and secondary vertices, and impact parameters of particle decays. In addition to this, it is a key
contributor to the measurements of particle lifetimes \cite{Kopciewicz_2022}.
\subsubsection{Angular Coverage}
\subsubsection{Triggering}
\subsubsection{Reconstruction Efficiency}
\subsubsection{Displaced Tracks and Vertices}
\subsubsection{Decay Time}
\subsection{Ring Imaging Cherenkov (RICH) Detector}
\subsection{Magnet} 
A warm dipole magnet is employed within the design of the LHCb in order to measure the momenta of charged particles. This measurement 
encompasses the forward acceptance of $\pm$ 250 mrad vertically and of $\pm$ 300 mrad horizontally
\subsection{Electromagnetic Calorimeter (ECAL)}
The ECAL thickness of 25 radiation lengths ensures the complete
containment of the high energy elecctromagnetic showers, as well as the acquisition
of an optimal energy resolution. The structure of the ECAL cells, comprising of 2 mm layers of lead and 4 mm scintillator layers is demonstrated in
Figure \ref{ECALStructure} below. The cells are said to have a "shashlik" structure, and the scintillation light readout is performed by Hamamatsu-R7899-20 photomultipliers \cite{AbellanBeteta:2020amj}. 
The ECAL comprises of a total of 6016 cells.
\begin{figure}[H]
    \centering
    \includegraphics[scale = 0.75]{ECALStructure.jpg}
    \caption{ECAL cell. Figure sourced from \cite{AbellanBeteta:2020amj}}
    \label{ECALStructure}
\end{figure}
\section{Data Analysis at the LHCb}
The Large Hadron Collider provides proton-proton collisions to the LHCb approximately 40 million times per second, thereby generating a significant amount of data. In order to retain the data from events that are deemed to be of interest for analyses, the plethora of data must be filtered efficiently, and the algorithms
implemented must be sufficiently intricate, so as to be able to manage the complexity of the data being processed. The LHCb experiment implements a data flow which enables the aforementioned objectives to be addressed. The flow of data through the LHCb system is further detailed in the sections that follow.
\subsection{The LHCb Data Flow}\label{LHCbDataFlow}
The collision events recorded by the LHCb detector proceed through various steps, each of which is controlled by an application that processes the data in a way that maximises the efficiency of data acquisition and also enhances the quality of the obtained. The data from the detector is first filtered through hardware and software components, known as the L0 trigger, and the high level trigger (HLT) respectively. Following this, the data is
reconstructed to transform the detector into objects such as tracks and clusters, which are stored in an output file in a 'DST' format. Data from this files is further filtered through a set of selections known as the stripping, the output of which is produced in either a DST or a '$\mu$DST' (micro-DST) format.\\
\\
A substantial amount of Monte Carlo (MC) simulated data is also generated in parallel to the detector data as part of the data flow. This is processed in a very similar manner to the detector data outlined above. Figure \ref{LHCbData} illustrates the abovementioned stages of the data flow and processing. The framework implemented to generate and process the simulated events described above, along with its constituent components are further elaborated upon in the subsequent sections
\begin{figure}[H]
    \centering
    \includegraphics[scale = 0.4]{LHCbDataFlow.jpg}
    \caption{LHCb Data Flow}
    \label{LHCbData}
\end{figure}
\subsection{The LHCb Simulation Framework}
The MC simulated data that is processed in parallel to the detector data flows through a similar pipeline to its counterpart, with necessary steps in place to mimic the proton-proton collisions and the detector response. The former, and the subsequent hadronisation and decay of the resultant particles 
are controlled by the Gauss application, which is responsible for calling the various compatible Monte Carlo generators such as Pythia and POWHEG, as well as to control applications such as EvtGen and Geant4, which describe the decays of simulated particles and simulate their traversal through and interaction with
the detector. On the other hand, the latter entails the transformation of the simulated hits made in the virtual detector into signals that mimic the real detector. This process is regulated by the Boole application, whose output is designed to closely match that of the real detector, such that the simulated data produced can be 
processed via the process described in Section \ref{LHCbDataFlow} above. 
\subsubsection{Gauss}
Gauss is a component of the simulation that intends to mimic the working of the spectrometer to enable the understanding of the experimental conditions and its performance \cite{Tlustos:913827}.
It comprises of two independent phases that are integrated and are typically run as a single job, but can be run separately if necessary. The first phase consists of the event generation
of proton-proton collisions and the decaying of the B mesons into channels of interest. This tool is interfaced to Pythia for the event production, and to a specialised decay package known as
EvtGen (see Section \ref{EvtGen} below). This phase also allows for the interfacing of other event generator engines if necessary. The particles produced are stored in the HepMC \cite{BUCKLEY2021107310} generic format that can be made persistent if the 
phase is run independently (i.e. in \textit{stand-alone} mode).\\
\\
The second phase consists of the tracking of the particles produced in the proton-prpton interactions within the detector. The physics processes undergone by the particles as they traverse the experimental setup are
regulated by the Geant4 toolkit (see Section \ref{Geant4} below), which interacts with Gauss using a host of interfaces and converters which enable the conversion of the LHCb detector geometry into the Geant4 geometry. In addition to this, it converts the output of the first phase of Gauss described above, to the Geant4 input format.\\
\\
Figure \ref{GaussSoftwareStructure} is a visual representation of the structure of the Gauss software that has been described above, while Figure \ref{GaussDependenices} depicts the various dependencies upon which the software has been built. These are further elaborated upon in the sections that follow. Further information on the architecture of the
Gauss software can also be obtained in \cite{Tlustos:913827} and \cite{Belyaev_2011}.
\begin{figure}[H]
    \begin{subfigure}{0.4\textwidth}
    \includegraphics[scale = 0.5]{GaussSoftwareStructure.jpg}
    \caption{ADD CAPTION}
    \label{GaussSoftwareStructure}
    \end{subfigure}
    \hfill
    \begin{subfigure}{0.4\textwidth}
        \includegraphics[scale = 0.55]{GaussDependenices.jpg}
        \caption{ADD CAPTION}
        \label{GaussDependenices}
    \end{subfigure}
    \hfill
\end{figure}
\subsubsection{EvtGen}\label{EvtGen}
The EvtGen package is an event generator that is designed for the simulation of the physics of $B$-decays. The package provides a framework to handle complex sequential and CP violating decays. The simulation of these decays proceeds
using decay amplitudes, rather than probabilities. The amplitude for each node in a decay is used to simulate the entire decay chain, including all angular and time dependent correlations \cite{LANGE2001152}. The implementation of each decay amplitude is independent
of how the parent particle was produced, or how the daughter particles are to decay. The package implements an algorithmm that simulates correlations given individual decay amplitudes, which involves summing over the spin degrees of freedom of the daughters of the B-meson, to perform event selection. A more
detailed overview of this procedure can be obtained in \cite{LANGE2001152}.
\subsubsection{Pythia}
The PYTHIA program is a standard tool for the generation of high-energy collisions \cite{SJOSTRAND2015159}. It constitutes a coherent set of
physics models for the evolution from a few-body hard process to a complex multihadronic final states, and contains numerous libraries of 
hard processes and models for initial and final state parton showers, multiple parton-parton interactions, beam remnants and particle decays. It 
also possesses a set of utilities and interfaces to external programs. The present version of the tool, PYTHIA 8, represents a complete rewrite in the C++ programming language, thereby contrasting
with its predecessors that were implemented in Fortran. The program presently only works with hadron-hadron and lepton-lepton collisions. The outgoing particles are produced in vacuum, and the simulation of the interaction of the produced particles with detector material is \textit{not} included in Pythia, and requires interfaces to external detector simulation codes, which can either be written by the user, or accomplished through the use of the HepMC interface. The hard processes, parton showers, multiple interactions,
beam remnants, and hadronisations that are to culminate in a complete event generator can be crudely divided into three stages, which are as follows:
\begin{itemize}
    \item The generation of a "process" that decides the nature of the event. This would generally be a "hard process" (i.e. $gg\rightarrow h_{0}, Z^{0}Z^{0}\rightarrow \mu^{+}\mu^{-} q\bar{q})$ that is calculated in perturbation theory. Only a small number of particles are defined at this level, merely to cover the key aspects of the event structure
    \item The generation of all subsequent activity at the partonic level, including the initial and final state radiation, multiple parton-parton interactions and the structure beam remnants. Much of this phenomena can be described accurately by perturbation theory, but the aspects that cannot be described in such a way also become important at this stage. Upon conclusion of this step, one can obtain a realistic partonic structure
    \item The hadronisation of the abovementioned parton configuration by string fragmentation, followed by the decays of unstable particles. This part is largely nonperturbative, and therefore requires comprehensive modelling and tuning, or parametrisations of existing data, as is necessary for decays. The conclusion of this stage provides the user access to realistic events
\end{itemize}
Orthogonal to the abovementioned subdivisions, there exists a broader classification wherein the user interaction with the generator occurs in three phases, namely:
\begin{itemize}
    \item Initialisation, where the tasks that are to be performed
    \item Generation of individual events (known as the "event loop")
    \item Finishing, where the final statistics are made available
\end{itemize}
One must note that the subdivisions (and orthogonality of the phases described above) are not rigid, and that multiple utilities and tasks extend across the abovementioned categories
\subsubsection{Geant4}\label{Geant4}
The Geant4 toolkit had been developed as the basis for the simulation framework, and as such, it is intended to have well-defined interfaces to other components, as well as to provide parts that can be used by these components. 
There exist seven key domains of the simulation of the traversal of particles through matter, namely:
\begin{itemize}
    \item Geometry and materials
    \item Particle interactions in matter
    \item Tracking management
    \item Digitisation and hit management
    \item Visualisation and visualisation framework
    \item User interface
\end{itemize}
Each of the domains described above are represented by class categories with coherent interfaces, and a corresponding working group with a well-defined responsibilities. The toolkit offers the user the ability to construct a geometric model 
with numerous components of varying shapes and materials. Furthermore, the user is able to define "sensitive" elements that enable the logging of information that is necessary to simulate detector responses.\\
\\
Geant4 also provides an extensive list of physics processes to model the behaviour of particles, enabling the user to choose between, add to, and modify a variety of implementations and approaches that are provided. In addition to this, the user is able to visualise the geometry
and tracks with a multitude of graphics systems and a user interface, which can be implemented over other systems of the user's choice. The structure of the toolkit can be described as a modular and hierarchical in nature, with dependencies forming links between the different sub-domains,
as illustrated in Figure \ref{Geant4Structure} below. Further detail on the nature of the sub-domains and dependencies depicted in this figure can be obtained in \cite{GEANT4:2002zbu}.
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.7]{Geant4Structure.jpg}
    \caption{ADD CAPTION}
    \label{Geant4Structure}
\end{figure}
\subsubsection{Gaudi}
The Gaudi software has been developed with the intention of being able to build the large variety of applications necessary for high energy physics experiments, ranging from the simulation of events to the user analysis and the event display. Its design exploits object-oriented methodologies in order to address key criteria pertaining to the separation of data and algorithms, as well as that of persistent and transient data, among other aspects. \\
\\
The Gaudi architecture can broadly classified into three categories as follows:
\begin{itemize}
\item[-] \textbf{Algorithms and Application Manager:} Algorithms are a series of generic interfaces that are the fundamental components of applications that process event data. The application manager sits atop a hierarchy of algorithms, and is responsible for the instantiation and calling of these 
\item[-]\textbf{Transient Data Stores:} The data objects required by the algorithms are organised in various transient data stores, which store event data, which is valid only during the time it takes to process one event. Likewise, detector data, that generally has a lifetime of multiple events, is stored within the transient detector store. There also exists a data store for statistical data, which typically has the lifetime of a complete job, known as a transient histogram and n-tuple store. 
\item[-] \textbf{Services:} Services are a category of components which offer all the services necessary by algorithms (e.g. those for managing the various transient stores, or for managing the conversion between transient and persistent data). Services that facilitate visualisation and event selection also exist within the architecture
\end{itemize}
Figure \ref{GaudiArchitecture} is a depiction of the Gaudi architecture described above. The key components (i.e. the algorithms, application manager, transient data stores, and services), as well as the relationship between these are indicated in this figure. Further detail on the nature of the components described in the diagram can be obtained in \cite{BARRAND200145} and \cite{Clemencic:2010zz}.
\begin{figure}[H]
    \centering 
    \includegraphics[scale=0.8]{GaudiArchitecture.jpg}
    \caption{ADD CAPTION}
    \label{GaudiArchitecture}
\end{figure}



